# Enterprise RAG Platform

**Agentic AI Knowledge Assistant with Multi-Source Data Ingestion**

Transform scattered knowledge into actionable intelligence. Unify Slack conversations, Confluence wikis, and documents into a single AI-powered knowledge base that delivers instant, source-verified answersâ€”no more hunting through wikis, PDFs, or chat history.

**Powered by OpenAI | Built on Flask | Designed for Enterprise Demo**

## ğŸŒŸ Platform Highlights

### **Production-Ready Ingestion Pipeline**
A complete data ingestion platform that handles multi-source knowledge bases with enterprise-grade reliability:

- ğŸ”„ **Multi-Source Ingestion** - Slack (API + exports), Confluence (Cloud + Server), PDF, Markdown, Text
- ğŸ’¾ **Immutable Storage** - Raw data preserved for re-indexing and auditing
- ğŸ“Š **Source Attribution** - Full metadata tracking from source to answer
- ğŸ”’ **Safe Operations** - Versioned indexes, automatic backups, atomic operations
- ğŸ“ˆ **Observable** - Structured logging, audit trails, ingestion metrics
- â™»ï¸ **Lifecycle Management** - Initialize, update, rebuild vector stores safely

### **Intelligent Agentic AI**
- ğŸ¤– **Intent Routing** - Automatically decides when to retrieve, refuse, or answer
- âœ… **Answer Verification** - Validates all claims against source documents
- ğŸ¯ **No Hallucinations** - Refuses to answer when sources don't support the query
- ğŸ“ **Source Citations** - Every answer linked to original content

### **Professional Frontend**
- ğŸ’¬ **ChatGPT-Style Interface** - Modern, responsive chat experience
- ğŸ“ **Document Upload** - Drag-and-drop with live re-indexing
- ğŸ¨ **Confidence Indicators** - Visual high/medium/low confidence badges
- ğŸ“± **Mobile-Optimized** - Fully responsive design

---

## ğŸš€ Quick Start

### Option 1: Full Stack (Recommended)

**Terminal 1 - Backend:**
```bash
cd enterprise-rag
pip install -r requirements.txt
python api_server.py
```

**Terminal 2 - Frontend:**
```bash
cd enterprise-rag-frontend
npm install
npm run dev
```

**Browser:** Navigate to **http://localhost:3000**

### Option 2: Ingestion Platform Only

```bash
cd enterprise-rag
pip install -r requirements.txt
python examples/ingestion_demo.py
```

---

## ğŸ“‚ Project Architecture

```
team_P1/
â”œâ”€â”€ enterprise-rag/                    # Python Backend
â”‚   â”œâ”€â”€ api_server.py                 # Flask API server
â”‚   â”œâ”€â”€ app.py                        # CLI interface
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                      # ğŸ†• Data Storage Layer
â”‚   â”‚   â”œâ”€â”€ metadata.py              #     Metadata models
â”‚   â”‚   â””â”€â”€ raw_storage.py           #     Immutable raw data storage
â”‚   â”‚
â”‚   â”œâ”€â”€ ingest/                       # ğŸ†• Ingestion Pipeline
â”‚   â”‚   â”œâ”€â”€ orchestrator.py          #     High-level API
â”‚   â”‚   â”œâ”€â”€ slack_ingestion.py       #     Slack API + exports
â”‚   â”‚   â”œâ”€â”€ confluence_ingestion.py  #     Confluence Cloud/Server
â”‚   â”‚   â”œâ”€â”€ document_ingestion.py    #     PDF/MD/TXT uploads
â”‚   â”‚   â”œâ”€â”€ processor.py             #     Unified processing
â”‚   â”‚   â”œâ”€â”€ vector_manager.py        #     Vector DB lifecycle
â”‚   â”‚   â””â”€â”€ logging_config.py        #     Observability
â”‚   â”‚
â”‚   â”œâ”€â”€ agent/                        # Agentic Control Flow
â”‚   â”‚   â”œâ”€â”€ intent_router.py         # Route queries intelligently
â”‚   â”‚   â””â”€â”€ answer_verifier.py       # Verify answer accuracy
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                          # RAG Pipeline
â”‚   â”‚   â”œâ”€â”€ qa_chain.py              # Question-answering chain
â”‚   â”‚   â””â”€â”€ retriever.py             # Vector retrieval
â”‚   â”‚
â”‚   â””â”€â”€ data/                         # Data Storage
â”‚       â”œâ”€â”€ raw/                      # ğŸ†• Immutable source data
â”‚       â”‚   â”œâ”€â”€ slack/               #     Slack conversations
â”‚       â”‚   â”œâ”€â”€ confluence/          #     Wiki pages
â”‚       â”‚   â””â”€â”€ uploads/             #     Uploaded files
â”‚       â”œâ”€â”€ vectorstore/              #     Chroma vector DB
â”‚       â””â”€â”€ ingestion_logs/           # ğŸ†• Audit trail
â”‚
â”œâ”€â”€ enterprise-rag-frontend/           # Next.js Frontend
â”‚   â”œâ”€â”€ app/                          # Pages & API routes
â”‚   â”œâ”€â”€ components/                   # React components
â”‚   â””â”€â”€ types/                        # TypeScript definitions
â”‚
â”œâ”€â”€ ğŸ“– Documentation/
â”‚   â”œâ”€â”€ QUICKSTART.md                 # 30-second setup
â”‚   â”œâ”€â”€ SETUP_GUIDE.md                # Detailed installation
â”‚   â”œâ”€â”€ ARCHITECTURE.md               # System design
â”‚   â”œâ”€â”€ DEMO_GUIDE.md                 # Testing scenarios
â”‚   â”‚
â”‚   â””â”€â”€ enterprise-rag/               # ğŸ†• Ingestion Platform Docs
â”‚       â”œâ”€â”€ README_INGESTION.md       #     Platform overview
â”‚       â”œâ”€â”€ PLATFORM_SUMMARY.md       #     Executive summary
â”‚       â”œâ”€â”€ QUICKSTART_INGESTION.md   #     Quick start guide
â”‚       â”œâ”€â”€ INGESTION_PLATFORM.md     #     Complete documentation
â”‚       â””â”€â”€ TECHNICAL_REFERENCE.md    #     Architecture deep dive
â”‚
â””â”€â”€ examples/
    â””â”€â”€ ingestion_demo.py             # ğŸ†• Runnable demonstration
```

---

## ğŸ¯ Core Capabilities

### ğŸ”„ Multi-Source Data Ingestion (NEW)

**Production-ready pipeline for enterprise knowledge bases:**

```python
from enterprise_rag.ingest.orchestrator import IngestionOrchestrator

orchestrator = IngestionOrchestrator()

# Ingest from multiple sources
orchestrator.ingest_slack_channel("C123456", days_history=30)
orchestrator.ingest_confluence_space("ENG", limit=500)
orchestrator.ingest_file("document.pdf", uploaded_by="user@example.com")

# Build vector index
orchestrator.initialize_vector_index()
```

**Key Features:**
- âœ… **Slack Integration** - Live API + historical exports, thread-aware
- âœ… **Confluence Integration** - Cloud & Server, HTMLâ†’text conversion
- âœ… **Docu:**
- Next.js 14 (App Router)
- TypeScript
- Tailwind CSS + shadcn/ui
- React 18

**Backend:**
- Flask (API server)
- LangChain (RAG orchestration)
- OpenAI GPT-4 (LLM)
- OpenAI text-embedding-3-small (Embeddings)
- ChromaDB (Vector database)
- Python 3.9+

**Ingestion Platform (NEW):**
- Slack SDK (slack-sdk)
- Atlassian Python API (atlassian-python-api)
- PyPDF (pypdf) for PDF extraction
### General Documentation
- **[QUICKSTART.md](QUICKSTART.md)** - Get started in 30 seconds
- **[SETUP_GUIDE.md](SETUP_GUIDE.md)** - Complete setup instructions
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - System design and data flow
- **[DEMO_GUIDE.md](DEMO_GUIDE.md)** - Testing and demo scenarios
- **[VISUAL_GUIDE.md](VISUAL_GUIDE.md)** - Visual diagrams
- **[PROJECT_SUMMARY.md](PROJECT_SUMMARY.md)** - Complete overview

### ğŸ†• Ingestion Platform Documentation
- *âœ… Success Checklist

### Basic Setup
- [ ] Backend running on port 8000
- [ ] Frontend running on port 3000
- [ ] Browser shows chat interface
- [ ] Status indicator shows "Connected"
- [ ] Can send a test message
- [ ] Can upload a document
- [ ] AI responds with sources and confidence

### Ingestion Platform (NEW)
- [ ] Run `python examples/ingestion_demo.py` successfully
- [ ] Raw data stored in `data/raw/{source}/`
- [ ] Ingestion logs created in `data/ingestion_logs/`
- [ ] Vector store initialized/updated
- [ ] Can query ingestion history
- [ ] Sources appear in chat responses
### ğŸ’¡ RAG Pipeline

**Retrieval-Augmented Generation with source tracking:**
- **Semantic Search** - ChromaDB vector database with OpenAI embeddings
- **Context Chunking** - Intelligent 700-char chunks with 100-char overlap
- **LLM Generation** - OpenAI GPT-4 for natural language answers
- **Metadata Flow** - Source type, author, timestamp, URL preserved

### ğŸ¨ Professional Frontend

**Production-ready Next.js interface:**
- **Modern UI** - ChatGPT-inspired chat experience
- **Type Safety** - Full TypeScript coverage
- **Real-time Updates** - Live chat with loading indicators
- **Document Upload** - Drag-and-drop with instant indexing
- **Responsive** - Mobile-first design, works everywhere

---

## ğŸ› ï¸ Technology Stack

**Frontend**:
- Next.js 14 (App Router)
- TypeScript
- Tailwind CSS
- React 18

**Backend:**
- Flask (API server)
- LangChain (RAG orchestration)
- OpenAI GPT-4 (LLM)
- OpenAI text-embedding-3-small (Embeddings)
- ChromaDB (Vector database)
- Python 3.9+

---

## ğŸ“– Documentation
### Frontend Demo
1. **Prepare**: Upload 2-3 documents before demo
2. **Test**: Try sample questions beforehand
3. **Highlight**: Show sources and confidence levels
4. **Upload**: Demonstrate live document upload
5. **Error**: Show graceful error handling

### Ingestion Platform Demo (NEW)
1. **Show Multi& Best Practices

### Security
- All API keys stored on backend only
- No LLM calls from frontend
- File upload validation (client & server)
- CORS configured for localhost
- No authentication (demo scope)

### Data Integrity (NEW)
- **Immutable Storage**: Raw data never overwritten
- **Audit Trails**: Every ingestion operation logged
- **Version CDeployment
- **Vercel** (recommended) - One-click Next.js deployment
- **Netlify** - Static site hosting
- **AWS Amplify** - Full-stack deployment
- **Docker** - Containerized deployment

### Backend Deployment
- **Google Cloud Run** - Serverless container platform
- **AWS EC2** - Virtual machine hosting
- **Heroku** - Platform as a service
- **Docker** - Containerized deployment

### Data & Ingestion
- **Local Storage** (current) - File-based for demo/small team
- **Cloud Storage** (future) - S3/GCS for raw data at scale
- **Managed Vector DB** (future) - Pinecone/Weaviate for distributed scale

See [SETUP_GUIDE.md](SETUP_GUIDE.md) and [INGESTION_PLATFORM.md](enterprise-rag/INGESTION_PLATFORM.md) for detailed
### Project Philosophy
This project combines demo readiness with production-quality architecture:

**Principles:**
- **Clean Abstractions** - Easy to understand and extend
- **Production Patterns** - Real-world best practices
- **Observable Systems** - Comprehensive logging and metrics
- **Honest Limitations** - Known issues documented with paths forward
- **Scalable Design** - Clear path from demo â†’ enterprise

### How to Extend

**Add New Data Source:**
1. Create `ingest/{source}_ingestion.py`
## ğŸŒŸ What Makes This Production-Ready

### Data Integrity
- âœ… **Immutable Storage** - Raw data preserved for re-indexing
- âœ… **Audit Trails** - Every operation logged with timestamps
- âœ… **Version Control** - Track index versions, enable rollback
- âœ… **Metadata Preservation** - Full provenance from source â†’ answer

### Operational Safety
- âœ… **Backup Strategy** - Automatic backups before destructive operations
- âœ… **Error Handling** - Graceful failures, partial successes preserved
- âœ… **Recovery Paths** - Rebuild corrupted data from raw sources
- âœ… **Atomic Operations** - No partial states, clean rollbacks

### Observability
- âœ… **Structured Logging** - Console + file, multiple severity levels
- âœ… **Metrics Tracking** - Document counts, success/failure rates
- âœ… **History Queries** - Audit ingestion operations over time
- âœ… **Debug9+
- Node.js 18+ (for frontend)
- Google API key (for embeddings & LLM)
- (Optional) Slack bot token
- (Optional) Confluence credentials

### Installation & Setup

See **[QUICKSTART.md](QUICKSTART.md)** for 30-second setup or **[SETUP_GUIDE.md](SETUP_GUIDE.md)** for detailed instructions.

**Quick version:**
```bash
# Clone
git clone https://github.com/Vishal-code-E/team_P1.git
cd team_P1

# Backend
cd enterprise-rag
pip install -r requirements.txt
cp .env.example .env  # Edit with your API keys
python api_server.py

# Frontend (separate terminal)
cd ../enterprise-rag-frontend
npm install
npm run dev
```

## ğŸ“ License

This project is open source and available under the MIT License.

---

## ğŸ”§ Common Issuesential features
- **Quality**: Production-ready code
- **Purpose**: Demo-ready and judge-friendly

---

## ğŸ“„ License

See individual component licenses. This project combines open-source technologies for educational/demo purposes.

---

**Built with discipline. Built like a professional product. Ready to impress.** ğŸš€
# AI Knowledge Base + Chatbot (RAG)

Company wikis are where docs go to die. Point this tool at your Confluence, PDFs and Slack history; ask "What's our AWS spending limit?" and get an instant, source-linked answer instead of ten blue links nobody clicks.

## ğŸ¯ Features

- **Multi-Source Knowledge Ingestion**: Load documents from PDFs, Confluence wikis, and Slack conversations
- **Intelligent Search**: Vector-based semantic search using OpenAI embeddings
- **Source Attribution**: Every answer includes citations with links to original sources
- **RAG-Powered Answers**: Uses Retrieval-Augmented Generation for accurate, context-aware responses
- **Modern Web UI**: Clean, responsive interface for chatting and document management
- **REST API**: Full API access for integration with other tools

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API key
- (Optional) Confluence credentials
- (Optional) Slack bot token

### Installation

1. Clone the repository:
```bash
git clone https://github.com/Vishal-code-E/team_P1.git
cd team_P1
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Configure environment variables:
```bash
cp .env.example .env
# Edit .env and add your API keys
```

4. Run the application:
```bash
python main.py
```

5. Open your browser to `http://localhost:8000`

## ğŸ”§ Configuration

Edit `.env` file with your credentials:

```env
# Required: OpenAI API Key
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Confluence Integration
CONFLUENCE_URL=https://your-domain.atlassian.net
CONFLUENCE_USERNAME=your_email@example.com
CONFLUENCE_API_TOKEN=your_confluence_api_token

# Optional: Slack Integration
SLACK_BOT_TOKEN=xoxb-your-slack-bot-token
SLACK_APP_TOKEN=xapp-your-slack-app-token
```

## ğŸ“– Usage

### Web Interface

1. **Upload PDFs**: Use the PDF upload section to add documents to your knowledge base
2. **Load Confluence**: Enter a space key to import wiki pages
3. **Load Slack**: Enter a channel ID to import message history
4. **Ask Questions**: Type your question in the chat interface and get instant answers with sources

### API Usage

#### Query the Knowledge Base
```bash
curl -X POST http://localhost:8000/api/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What is our AWS spending limit?"}'
```

#### Upload PDFs
```bash
curl -X POST http://localhost:8000/api/upload/pdf \
  -F "files=@document.pdf"
```

#### Load Confluence Space
```bash
curl -X POST http://localhost:8000/api/load/confluence \
  -H "Content-Type: application/json" \
  -dBackend won't start
```bash
# Ensure dependencies installed
cd enterprise-rag
pip install -r requirements.txt

# Check API key in .env
grep GOOGLE_API_KEY .env
```

### Frontend won't start
```bash
# Clear cache and reinstall
cd enterprise-rag-frontend
rm -rf node_modules .next
npm install
npm run dev
```

### Ingestion fails silently
```bash
# Check logs
cat logs/ingestion_*.log | grep ERROR

# Run demo to verify setup
python examples/ingestion_demo.py
```

### Confluence connection issues
- Verify URL includes full domain: `https://your-domain.atlassian.net`
- Ensure API token has read permissions
- For Cloud, use email as username

### Slack integration issues
- Bot token needs `channels:history` scope
- Bot must be added to channel
- Use channel ID (C123456), not name

### Vector store corrupted
```python
# Rebuild from raw data
from enterprise_rag.ingest.orchestrator import IngestionOrchestrator
orchestrator = IngestionOrchestrator()
orchestrator.rebuild_vector_index(backup=True)
```

---

## ğŸ“§ Support & Community

- **Issues**: [GitHub Issues](https://github.com/Vishal-code-E/team_P1/issues)
- **Documentation**: See `/docs` folder and `enterprise-rag/*.md` files
- **Examples**: Check `examples/` directory for runnable demos

---

## ğŸ™ Acknowledgments

Built with these excellent open-source tools:
- **LangChain** - RAG orchestration framework
- **ChromaDB** - Vector database
- **OpenAI** - GPT-4 LLM and text-embedding-3-small
- **Next.js** - React framework
- **Flask** - Python web framework
- **Slack SDK** - Slack API integration
- **Atlassian Python API** - Confluence integration

---

**Questions? Start with [QUICKSTART.md](QUICKSTART.md) or [enterprise-rag/README_INGESTION.md](enterprise-rag/README_INGESTION.md)**
    â”‚  System  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Vector Store  â”‚
    â”‚  (ChromaDB)   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Document Connectors    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ PDF Loader            â”‚
    â”‚ â€¢ Confluence Connector  â”‚
    â”‚ â€¢ Slack Connector       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

- **FastAPI Backend**: REST API for all operations
- **ChromaDB**: Vector database for semantic search
- **LangChain**: RAG pipeline and document processing
- **OpenAI**: Embeddings (text-embedding-3-small) and LLM (GPT-4)

## ğŸ“š API Documentation

Once running, visit `http://localhost:8000/docs` for interactive API documentation.

## ğŸ”’ Security Notes

- Never commit your `.env` file
- Keep API keys secure
- Use environment variables for all sensitive data
- Confluence and Slack tokens should have minimal required permissions

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ†˜ Troubleshooting

### "No such file or directory" errors
Make sure all required directories exist:
```bash
mkdir -p data/chroma uploads static templates
```

### Confluence connection issues
- Verify your Confluence URL includes the full domain
- Ensure API token has read permissions
- For Confluence Cloud, use your email as username

### Slack integration issues
- Bot token must have `channels:history` scope
- Ensure bot is added to the channel you want to read
- Use channel ID, not channel name

## ğŸ“§ Support

For issues and questions, please open an issue on GitHub.
